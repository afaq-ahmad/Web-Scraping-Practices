{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target: Airline Name and Email Address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have not completly run the program as I am writing it for learning purpose. If you have any issue contact me at afaq.ahmad100@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tested on Anaconda 2.7 windows. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the Airline Directory by Country:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import urllib\n",
    "import urllib3\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "urllib3.disable_warnings()\n",
    "urlpage='https://www.airlines-inform.com/countries/'\n",
    "headers = {'User-Agent':'Mozilla/5.0'}\n",
    "page = requests.get(urlpage, headers=headers, verify=False)\n",
    "data = page.content \n",
    "soup = BeautifulSoup(data, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vse=soup.find_all(class_=\"vse-strany\")\n",
    "listcou=[]\n",
    "lin=vse[0].find_all('a')\n",
    "for i in range(len(lin)):\n",
    "    abc=lin[i].get('href')\n",
    "    listcou.append(abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(listcou)\n",
    "listairlines=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ------ 3\n",
      "1 ------ 4\n",
      "2 ------ 6\n",
      "3 ------ 8\n",
      "4 ------ 9\n",
      "5 ------ 11\n",
      "6 ------ 18\n",
      "7 ------ 20\n",
      "8 ------ 22\n",
      "9 ------ 41\n",
      "10 ------ 47\n",
      "11 ------ 49\n",
      "12 ------ 52\n",
      "13 ------ 53\n",
      "14 ------ 56\n",
      "15 ------ 57\n",
      "16 ------ 62\n",
      "17 ------ 64\n",
      "18 ------ 65\n",
      "19 ------ 67\n",
      "20 ------ 71\n",
      "21 ------ 72\n",
      "22 ------ 81\n",
      "23 ------ 82\n",
      "24 ------ 87\n",
      "25 ------ 88\n",
      "26 ------ 89\n",
      "27 ------ 93\n",
      "28 ------ 94\n",
      "29 ------ 143\n",
      "30 ------ 144\n",
      "31 ------ 145\n",
      "32 ------ 151\n",
      "33 ------ 195\n",
      "34 ------ 204\n",
      "35 ------ 205\n",
      "36 ------ 208\n",
      "37 ------ 214\n",
      "38 ------ 215\n",
      "39 ------ 218\n",
      "40 ------ 219\n",
      "41 ------ 221\n",
      "42 ------ 224\n",
      "43 ------ 226\n",
      "44 ------ 231\n",
      "45 ------ 236\n",
      "46 ------ 237\n",
      "47 ------ 240\n",
      "48 ------ 244\n",
      "49 ------ 255\n",
      "50 ------ 256\n",
      "51 ------ 259\n",
      "52 ------ 260\n",
      "53 ------ 261\n",
      "54 ------ 262\n",
      "55 ------ 263\n",
      "56 ------ 264\n",
      "57 ------ 266\n",
      "58 ------ 269\n",
      "59 ------ 282\n",
      "60 ------ 283\n",
      "61 ------ 285\n",
      "62 ------ 288\n",
      "63 ------ 290\n",
      "64 ------ 296\n",
      "65 ------ 314\n",
      "66 ------ 317\n",
      "67 ------ 326\n",
      "68 ------ 327\n",
      "69 ------ 329\n",
      "70 ------ 330\n",
      "71 ------ 332\n",
      "72 ------ 333\n",
      "73 ------ 334\n",
      "74 ------ 335\n",
      "75 ------ 337\n",
      "76 ------ 339\n",
      "77 ------ 344\n",
      "78 ------ 354\n",
      "79 ------ 372\n",
      "80 ------ 385\n",
      "81 ------ 387\n",
      "82 ------ 392\n",
      "83 ------ 397\n",
      "84 ------ 408\n",
      "85 ------ 429\n",
      "86 ------ 434\n",
      "87 ------ 445\n",
      "88 ------ 449\n",
      "89 ------ 450\n",
      "90 ------ 451\n",
      "91 ------ 459\n",
      "92 ------ 462\n",
      "93 ------ 467\n",
      "94 ------ 469\n",
      "95 ------ 471\n",
      "96 ------ 474\n",
      "97 ------ 479\n",
      "98 ------ 483\n",
      "99 ------ 484\n",
      "100 ------ 484\n",
      "101 ------ 486\n",
      "102 ------ 488\n",
      "103 ------ 495\n",
      "104 ------ 500\n",
      "105 ------ 504\n",
      "106 ------ 505\n",
      "107 ------ 506\n",
      "108 ------ 507\n",
      "109 ------ 518\n",
      "110 ------ 521\n",
      "111 ------ 524\n",
      "112 ------ 525\n",
      "113 ------ 528\n",
      "114 ------ 530\n",
      "115 ------ 539\n",
      "116 ------ 540\n",
      "117 ------ 548\n",
      "118 ------ 553\n",
      "119 ------ 555\n",
      "120 ------ 560\n",
      "121 ------ 561\n",
      "122 ------ 570\n",
      "123 ------ 573\n",
      "124 ------ 574\n",
      "125 ------ 577\n",
      "126 ------ 578\n",
      "127 ------ 580\n",
      "128 ------ 584\n",
      "129 ------ 587\n",
      "130 ------ 592\n",
      "131 ------ 601\n",
      "132 ------ 605\n",
      "133 ------ 613\n",
      "134 ------ 614\n",
      "135 ------ 615\n",
      "136 ------ 616\n",
      "137 ------ 620\n",
      "138 ------ 670\n",
      "139 ------ 671\n",
      "140 ------ 672\n",
      "141 ------ 673\n",
      "142 ------ 675\n",
      "143 ------ 676\n",
      "144 ------ 679\n",
      "145 ------ 680\n",
      "146 ------ 681\n",
      "147 ------ 682\n",
      "148 ------ 682\n",
      "149 ------ 687\n",
      "150 ------ 688\n",
      "151 ------ 689\n",
      "152 ------ 690\n",
      "153 ------ 701\n",
      "154 ------ 721\n",
      "155 ------ 723\n",
      "156 ------ 724\n",
      "157 ------ 728\n",
      "158 ------ 730\n",
      "159 ------ 731\n",
      "160 ------ 740\n",
      "161 ------ 749\n",
      "162 ------ 751\n",
      "163 ------ 757\n",
      "164 ------ 760\n",
      "165 ------ 765\n",
      "166 ------ 783\n",
      "167 ------ 784\n",
      "168 ------ 785\n",
      "169 ------ 790\n",
      "170 ------ 801\n",
      "171 ------ 802\n",
      "172 ------ 803\n",
      "173 ------ 804\n",
      "174 ------ 827\n",
      "175 ------ 836\n",
      "176 ------ 856\n",
      "177 ------ 906\n",
      "178 ------ 909\n",
      "179 ------ 910\n",
      "180 ------ 911\n",
      "181 ------ 923\n",
      "182 ------ 927\n",
      "183 ------ 928\n",
      "184 ------ 930\n",
      "185 ------ 931\n",
      "186 ------ 933\n"
     ]
    }
   ],
   "source": [
    "for og in range(0,len(listcou)):\n",
    "    page = requests.get(listcou[og], headers=headers, verify=False)\n",
    "    data = page.content \n",
    "    soup = BeautifulSoup(data, \"html.parser\")\n",
    "    airlines=soup.find_all('a',class_=\"airlines\")\n",
    "    for i in range(len(airlines)):\n",
    "        listairlines.append(airlines[i].get('href'))\n",
    "    print og,'------',len(listairlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the Airline Directory by continent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listurk=[]\n",
    "urk='https://www.airlines-inform.com/world_airlines/'\n",
    "page = requests.get(urk, headers=headers, verify=False)\n",
    "data = page.content \n",
    "soup = BeautifulSoup(data, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "listurk=[]\n",
    "li=soup.find_all('li')\n",
    "for ms in range(len(li)):\n",
    "    vxz=li[ms].find('a').get('href')\n",
    "    listurk.append(vxz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.airlines-inform.com/world_airlines/north_america/\n",
      "162\n",
      "https://www.airlines-inform.com/world_airlines/central_america/\n",
      "0\n",
      "https://www.airlines-inform.com/world_airlines/south_america/\n",
      "69\n",
      "https://www.airlines-inform.com/world_airlines/west_asia/\n",
      "67\n",
      "https://www.airlines-inform.com/world_airlines/east_asia/\n",
      "93\n",
      "https://www.airlines-inform.com/world_airlines/south_east_asia/\n",
      "87\n",
      "https://www.airlines-inform.com/world_airlines/west_europe/\n",
      "151\n",
      "https://www.airlines-inform.com/world_airlines/east_europe/\n",
      "56\n",
      "https://www.airlines-inform.com/world_airlines/russia/\n",
      "60\n",
      "https://www.airlines-inform.com/world_airlines/cis/\n",
      "58\n",
      "https://www.airlines-inform.com/world_airlines/africa/\n",
      "113\n",
      "https://www.airlines-inform.com/world_airlines/australia/\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "initurl='https://www.airlines-inform.com'\n",
    "listurk1=[]\n",
    "for ih in range(len(listurk)):\n",
    "    urls=initurl+listurk[ih]\n",
    "    print urls\n",
    "    page = requests.get(urls, headers=headers, verify=False)\n",
    "    data = page.content \n",
    "    soup = BeautifulSoup(data, \"html.parser\")\n",
    "    tbody=soup.find_all('tbody')[0].find_all('a',class_=\"airlines\")\n",
    "    for ia in range(len(tbody)):\n",
    "        tbodyhref=tbody[ia].get('href')\n",
    "        listurk1.append(tbodyhref)\n",
    "    print len(tbody)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping the email address of Airlines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "afa=listurk1\n",
    "for i in range(0,len(listairlines)):\n",
    "    afa.append(listairlines[i])\n",
    "    \n",
    "# deleting duplicates\n",
    "from collections import OrderedDict\n",
    "lista3=list(OrderedDict.fromkeys(afa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for jh in range(0,len(lista3)):\n",
    "    dataset0=['-']*3\n",
    "    print jh,'--',initurl+lista3[jh]\n",
    "    page = requests.get(initurl+lista3[jh], headers=headers, verify=False)\n",
    "    data = page.content \n",
    "    soup = BeautifulSoup(data, \"html.parser\")\n",
    "    details=soup.find_all(class_=\"catalog-element\")[0]\n",
    "    name=details.find('h1').text\n",
    "    dataset0[0]=name\n",
    "    details0=details.find_all(class_=\"detail_air\")[0].find_all('b')\n",
    "    for nm in range(len(details0)):\n",
    "        if details0[nm].text=='Country:':\n",
    "            Country=((details0[nm].next_element).next_element).encode('ascii', 'ignore')\n",
    "            dataset0[1]=Country\n",
    "        if details0[nm].text=='E-mail:':\n",
    "            mail=((details0[nm].next_element).next_element).encode('ascii', 'ignore')\n",
    "            dataset0[2]=mail\n",
    "    print dataset0\n",
    "    dataset1.append(dataset0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "import warnings\n",
    "from openpyxl import Workbook\n",
    "\n",
    "wb = Workbook(write_only=True)\n",
    "ws = wb.create_sheet()\n",
    "\n",
    "# now we'll fill it with 100 rows x 200 columns\n",
    "for irow in dataset1:\n",
    "    ws.append(irow)\n",
    "# save the file\n",
    "wb.save('Files/airlines-inform.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
